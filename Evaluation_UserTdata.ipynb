{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "import botocore \n",
    "from sagemaker import get_execution_role \n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import s3fs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "import re \n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "import chars2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role() \n",
    "data_location = 's3://{}/{}'.format('sagemaker-060720', 'true_safety.csv') \n",
    "true_safety = pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_safety['allergens'] = \"na\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "isaac = 'milk, cheese, soy, cream, eggs'\n",
    "jj = 'peanuts, whey, tree nuts'\n",
    "chelsea = 'Shrimp, Prawns, Lobster, Crab'\n",
    "emma = 'wheat, barely, rye triticale'\n",
    "silvia = 'garlic, avocado, celery'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_safety.loc[0:10, 'allergens'] = emma\n",
    "true_safety.loc[10:21, 'allergens'] = silvia\n",
    "true_safety.loc[21:45, 'allergens'] = isaac\n",
    "true_safety.loc[45:55, 'allergens'] = jj\n",
    "true_safety.loc[55:65, 'allergens'] = chelsea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Name</th>\n",
       "      <th>Label</th>\n",
       "      <th>allergens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>emma-1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>wheat, barely, rye triticale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>emma-2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>wheat, barely, rye triticale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>emma-3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>wheat, barely, rye triticale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>emma-4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>wheat, barely, rye triticale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>emma-5.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>wheat, barely, rye triticale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item        Name  Label                     allergens\n",
       "0     0  emma-1.jpg      0  wheat, barely, rye triticale\n",
       "1     1  emma-2.jpg      0  wheat, barely, rye triticale\n",
       "2     2  emma-3.jpg      0  wheat, barely, rye triticale\n",
       "3     3  emma-4.jpg      0  wheat, barely, rye triticale\n",
       "4     4  emma-5.jpg      1  wheat, barely, rye triticale"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_safety.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean words \n",
    "def clean_word (word):\n",
    "    \n",
    "    c_word = word.lower().strip() # lowercase and remove white space\n",
    "    c_word = re.sub('[^a-zA-Z]+', '', c_word) # remove anything that's not a letter\n",
    "    if len(c_word) < 2: # remove words that are less than 2 characters\n",
    "        c_word = \"\" \n",
    "    \n",
    "    return c_word\n",
    "\n",
    "# clean string of words\n",
    "def clean_text (text, split=True):\n",
    "    \n",
    "    if split == False: # for ocr output\n",
    "        c_text = [clean_word(w) for w in text] # already split and clean words\n",
    "        \n",
    "    else: \n",
    "        c_text = re.sub('[0-9]', ' ', text) # replace numbers with space \n",
    "        c_text = re.sub('['+string.punctuation+']', ' ', c_text) # replace punctuation with space\n",
    "        c_text = [clean_word(w) for w in c_text.split()] # split on spaces and clean words\n",
    "      \n",
    "    c_text = sorted(list(filter(None, set(c_text)))) # remove empty words and get unique values and sort\n",
    "    \n",
    "    return c_text\n",
    "\n",
    "# safety of product\n",
    "def safety (allergens, ingredients):\n",
    "    vectorizer = CountVectorizer(analyzer='char')\n",
    "    if len(ingredients) == 0 or ingredients == ['']:\n",
    "        return { \"ocr\": ingredients,\n",
    "                 \"target\": allergens,\n",
    "                 \"matchy\": \"Nothing detected.\",\n",
    "                 \"result\": \"Nothing detected. Please retake photo.\" }\n",
    "    else:\n",
    "        words = allergens + ingredients # create list of allergens and ingredients \n",
    "        word_embeddings = vectorizer.fit_transform(words) # embeddings for allergens and ingredients \n",
    "        cos_sims = cosine_similarity(word_embeddings[:len(allergens)], word_embeddings[len(allergens):]) # cos sim of allergens and ingredients \n",
    "        counts = [sum(all_sims) for all_sims in cos_sims > 0.85] # counts of ingredients with a 0.75 greater cos sim to each allergen \n",
    "        b = [c!=0 for c in counts] # boolean of counts\n",
    "        matches = np.array(allergens)[b] # dangerous ingredients\n",
    "        if sum(counts) > 0:\n",
    "            return { \"ocr\": ingredients,\n",
    "                     \"target\": allergens,\n",
    "                     \"matchy\": list(matches),\n",
    "                     \"result\": \"unsafe\" }\n",
    "        else: return { \"ocr\": ingredients,\n",
    "                       \"target\": allergens,\n",
    "                       \"matchy\": \"None of the ingredients match your allergens.\",\n",
    "                       \"result\": \"safe\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safety_chars (allergens, ingredients):\n",
    "    if len(ingredients) == 0 or ingredients == ['']:\n",
    "        return \"Nothing detected. Please retake photo.\"\n",
    "    else:\n",
    "        c2v_model = chars2vec.load_model('eng_50')\n",
    "        words = allergens + ingredients # create list of allergens and ingredients \n",
    "        word_embeddings = c2v_model.vectorize_words(words) # embeddings for allergens and ingredients \n",
    "        cos_sims = cosine_similarity(word_embeddings[:len(allergens)], word_embeddings[len(allergens):]) # cos sim of allergens and ingredients \n",
    "        counts = [sum(all_sims) for all_sims in cos_sims > 0.75] # counts of ingredients with a 'sim' greater cos sim to each allergen \n",
    "        if sum(counts) > 0:\n",
    "            return \"unsafe\"\n",
    "        else: return \"safe\"\n",
    "        \n",
    "def safety_count (allergens, ingredients):\n",
    "    if len(ingredients) == 0 or ingredients == ['']:\n",
    "        return \"Nothing detected. Please retake photo.\" \n",
    "    else:\n",
    "        vectorizer = CountVectorizer(analyzer='char')\n",
    "        words = allergens + ingredients # create list of allergens and ingredients \n",
    "        word_embeddings = vectorizer.fit_transform(words) # embeddings for allergens and ingredients \n",
    "        cos_sims = cosine_similarity(word_embeddings[:len(allergens)], word_embeddings[len(allergens):]) # cos sim of allergens and ingredients \n",
    "        counts = [sum(all_sims) for all_sims in cos_sims > 0.75] # counts of ingredients with a 'sim' greater cos sim to each allergen \n",
    "        if sum(counts) > 0:\n",
    "            return \"unsafe\" \n",
    "        else: return \"safe\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 1 25 26\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "for img_path in fs.ls('s3://sagemaker-060720/Images/'):\n",
    "    \n",
    "    file_name = img_path[24:]\n",
    "    true_vals = true_safety.loc[true_safety.Name == file_name,]\n",
    "    label = true_vals.Label.values[0]\n",
    "    allergens = true_vals.allergens.values[0]\n",
    "    \n",
    "    with fs.open(f's3://'+img_path) as f:\n",
    "        \n",
    "        pil_img = Image.open(f)\n",
    "        buff = BytesIO()\n",
    "        pil_img.save(buff, format=\"JPEG\")\n",
    "        img_bytes = buff.getvalue()\n",
    "        \n",
    "        tex_client = boto3.client('textract')\n",
    "        tex_dect = tex_client.detect_document_text(Document={\"Bytes\":img_bytes})\n",
    "        \n",
    "        tex_text = [text['Text'] if text['BlockType']=='WORD' else \"\" for text in tex_dect['Blocks']]\n",
    "        \n",
    "        tex_ingredients = clean_text(tex_text, split=False)\n",
    "        \n",
    "        clean_allergens = clean_text(allergens)\n",
    "        \n",
    "#         tex_results = safety(clean_allergens, tex_ingredients)\n",
    "\n",
    "#         results.append(tex_results)\n",
    "        \n",
    "#         tex_safety = tex_results['result']\n",
    "\n",
    "        tex_safety = safety_count(clean_allergens, tex_ingredients)\n",
    "        \n",
    "        if (tex_safety==\"safe\") & (label==1):\n",
    "            tp += 1\n",
    "        if (tex_safety==\"safe\") & (label==0):\n",
    "            fp += 1\n",
    "        if (tex_safety==\"unsafe\") & (label==0):\n",
    "            tn += 1\n",
    "        if (tex_safety==\"unsafe\") & (label==1):\n",
    "            fn += 1\n",
    "\n",
    "print(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tp/(tp+fp)\n",
    "r = tp/(tp+fn)\n",
    "if p==0 and r==0:\n",
    "    f1score = 0\n",
    "else: f1score = (2*p*r)/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47058823529411764"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3157894736842105"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038461538461538464"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp/(fp+tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "28 2 24 10 | 30 2 24 8\n",
    "\n",
    "0.8235294117647058 | 0.8571428571428572\n",
    "\n",
    "0.7368421052631579 | 0.7894736842105263\n",
    "\n",
    "0.07692307692307693 | 0.07692307692307693\n",
    "\n",
    "\n",
    "12 1 25 26 | "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_ocr",
   "language": "python",
   "name": "conda_ocr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
